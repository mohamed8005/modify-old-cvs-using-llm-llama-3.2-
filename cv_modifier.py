import os
import sys
import argparse
import requests
import markdown2
import pdfkit
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings


# Function to interact with the Llama 3 API via OpenRouter
def llama3_generate(prompt, api_key, model="meta-llama/llama-3.2-11b-vision-instruct:free", temperature=0.7):
    """
    Interacts with the Llama 3 API to generate content based on the given prompt.
    """
    url = "https://openrouter.ai/api/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature
    }

    response = requests.post(url, json=payload, headers=headers)
    if response.status_code == 200:
        return response.json()['choices'][0]['message']['content']
    else:
        raise Exception(f"Error: {response.status_code}, {response.text}")


# Function to load PDF documents from a file or directory
def load_pdfs(file_path=None, dir_path=None):
    """
    Loads content from PDF files located in the specified file or directory.
    """
    documents = []

    if file_path and os.path.isfile(file_path) and file_path.endswith(".pdf"):
        loader = PyPDFLoader(file_path)
        documents.extend(loader.load())
    elif dir_path and os.path.isdir(dir_path):
        for file_name in os.listdir(dir_path):
            if file_name.endswith(".pdf"):
                loader = PyPDFLoader(os.path.join(dir_path, file_name))
                documents.extend(loader.load())
    else:
        raise ValueError("You must provide either a valid --file or --dir containing PDFs.")
    
    return documents


# Function to format LLM-generated Markdown content into HTML
def format_to_html_with_markdown(cv_content):
    """
    Converts Markdown content generated by the LLM into styled HTML with better alignment and visuals.
    """
    html_content = markdown2.markdown(cv_content)
    styled_html = f"""
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Generated CV</title>
        <style>
            /* General Page Styling */
            body {{
                font-family: 'Arial', sans-serif;
                margin: 40px;
                line-height: 1.6;
                color: #333;
                background-color: #ffffff;
            }}
            /* Header Section */
            h1 {{
                color: #34495e;
                text-align: center;
                font-size: 2.5em;
                margin-bottom: 10px;
            }}
            h2, h3 {{
                color: #2980b9;
                margin-top: 30px;
                font-size: 1.5em;
            }}
            /* Section Separator */
            hr {{
                border: 0;
                height: 2px;
                background: linear-gradient(to right, #2980b9, #f4f4f4, #2980b9);
                margin: 20px 0;
            }}
            /* Content Styling */
            p {{
                margin: 10px 0;
                font-size: 1em;
            }}
            ul {{
                padding-left: 20px;
                margin: 10px 0;
            }}
            li {{
                margin-bottom: 8px;
                font-size: 1em;
            }}
            /* Footer */
            footer {{
                text-align: center;
                margin-top: 40px;
                color: #666;
                font-size: 0.9em;
            }}
        </style>
    </head>
    <body>
        <h1>Professional CV</h1>
        <hr>
        {html_content}
        <footer>
            
        </footer>
    </body>
    </html>
    """
    return styled_html


# Function to save HTML content as a PDF
def save_html_to_pdf(html_content, output_path):
    """
    Converts the given HTML content into a PDF file.
    """
    pdfkit.from_string(html_content, output_path)


# Main script
if __name__ == "__main__":
    # Argument parser setup
    parser = argparse.ArgumentParser(description="Generate a professional CV using Llama 3 API via OpenRouter.")
    parser.add_argument("--file", type=str, help="Path to a single PDF file.")
    parser.add_argument("--dir", type=str, help="Path to a directory containing PDF files.")
    parser.add_argument("--api-key", type=str, required=True, help="API key for OpenRouter.")
    args = parser.parse_args()

    # Validate input arguments
    if not args.file and not args.dir:
        print("Error: You must specify either --file or --dir.")
        sys.exit(1)

    # Load documents
    try:
        documents = load_pdfs(file_path=args.file, dir_path=args.dir)
    except ValueError as e:
        print(e)
        sys.exit(1)

    # Embed documents
    print("Embedding documents...")
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.from_documents(documents, embeddings)
    retriever = vectorstore.as_retriever()

    # Define multiple prompts and temperatures
    prompts = [
        "Generate a professional CV in Markdown format highlighting key achievements. in the input language",
        "Generate a detailed CV with a professional tone and structured sections. in the input language",
        "Generate a professional CV in Markdown format, the cv must include all the informations in the old one and make only the writting better and more professional without leaving important details. in the input language",
        "give directly a cv without representing it ,in markdown format ,and give all the important details about the cv and with good language , in the original language"
    ]
    temperatures = [0.3, 0.7, 1.0]

    # Generate CVs for each prompt and temperature
    for prompt in prompts:
        for temp in temperatures:
            print(f"Generating CV with prompt: '{prompt}' and temperature: {temp}")
            try:
                context = "\n".join([doc.page_content for doc in retriever.get_relevant_documents(prompt)])
                full_prompt = f"{context}\n\n{prompt}"
                generated_cv = llama3_generate(full_prompt, args.api_key, temperature=temp)

                # Convert Markdown output to styled HTML
                html_content = format_to_html_with_markdown(generated_cv)

                # Save the styled HTML as a PDF
                output_path = f"generated_cv_temp_{temp}_prompt_{prompts.index(prompt)}.pdf"
                save_html_to_pdf(html_content, output_path)
                print(f"Generated CV saved to {output_path}")
            except Exception as e:
                print(f"Error with prompt: '{prompt}' and temperature: {temp}: {e}")
